{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_78hap_vbDaj"
   },
   "source": [
    "#Fish2Eat Model - Capstone Project\n",
    "\n",
    "####Objective: To classify fish species from images and provide recipes, nutritional information, and food pairing suggestions.\n",
    "\n",
    "####Target Accuracy: Achieve at least 75% accuracy in identifying fish species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZH31KjNbS1h"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uC_976ddiXSw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imghdr\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import image_dataset_from_directory, load_img, img_to_array\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zslZDiYpcGPH"
   },
   "source": [
    "#Step 1: Access Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Fp0PhfJC_I0",
    "outputId": "b711d8b2-fd16-488b-faef-19e4bea6e2a8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUD1BfaFG9lO"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/My Drive/Colab Notebooks/capstone/dataset.zip\" -d \"/content/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9QvC8ePHLZ7",
    "outputId": "397cecd3-1678-4aaf-c0d3-ebc38c48e2df"
   },
   "outputs": [],
   "source": [
    "!ls /content/dataset/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpUqHpd5lRbw"
   },
   "outputs": [],
   "source": [
    "base_dir = \"/content/dataset/dataset\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONdWUx-9mDJM",
    "outputId": "acc629a7-4ffc-4d9f-9ae5-c955b3acc6f7"
   },
   "outputs": [],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dj9NtEoNmHqb",
    "outputId": "31749ce4-13ef-492a-be09-44634b948c85"
   },
   "outputs": [],
   "source": [
    "os.listdir(valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBQ6yyNmcNKs"
   },
   "source": [
    "#Step 2: Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsolAxwsVjEY"
   },
   "outputs": [],
   "source": [
    "image_extensions = [\".png\", \".jpg\"]\n",
    "img_type_supported_tensorflow = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "\n",
    "for filepath in Path(base_dir).rglob(\"*\"):\n",
    "    if filepath.is_file():\n",
    "        if filepath.suffix.lower() in image_extensions:\n",
    "            img_type = imghdr.what(filepath)\n",
    "            if img_type is None or img_type not in img_type_supported_tensorflow:\n",
    "                print(f\"{filepath} is not valid, delete this image.\")\n",
    "                os.remove(filepath)\n",
    "        else:\n",
    "            print(f\"{filepath} has an invalid file extension, delete this image.\")\n",
    "            os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xhZ2zrwcYGQ"
   },
   "source": [
    "#Step 3: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2q7mwLNMxR1"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SHUFFLE_BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = (128, 128)\n",
    "NUM_CLASSES = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqdocPx3nmgb",
    "outputId": "e8c2f5c4-11e2-40e3-a01f-f8e59eafe4c6"
   },
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg5b7iEbcZN6"
   },
   "source": [
    "#Step 4: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u32NoIWZjlnR"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def augment(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = (train_dataset\n",
    "    .map(augment)\n",
    "    .cache()\n",
    "    .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = (validation_dataset\n",
    "    .map(lambda x, y: (x / 255.0, y))\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scRc-H4ucbo8"
   },
   "source": [
    "#Step 5: Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "AffR0YiQiXS_",
    "outputId": "01e355e6-c690-4a82-8d7e-d1a3f3d80abd"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(512, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    Dropout(0.5),\n",
    "    Dense(15, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWlpQh-dreCd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=1e-4),\n",
    "          loss = 'categorical_crossentropy',\n",
    "          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juwf9-AZDfdj"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7PIPNqdckx6"
   },
   "source": [
    "#Step 6: Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDS4gDbMiXTB",
    "outputId": "45240cec-d22e-4df5-a1a3-e5b875964b1e"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cx3_MIycrr4"
   },
   "source": [
    "#Step 7: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "oKgo-dWJiXTB",
    "outputId": "dd3e86c9-3f19-4d02-ae46-04b3a2a66cf4"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Training and validation accuracy')\n",
    "\n",
    "for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], [\"Accuracy\", \"Loss\"])):\n",
    "    ax[i].plot(epochs, data[0], 'r', label=\"Training \" + label)\n",
    "    ax[i].plot(epochs, data[1], 'b', label=\"Validation \" + label)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfRafytkcu5k"
   },
   "source": [
    "#Step 8: Save and Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "CjssYQ9S_WQj",
    "outputId": "4e800150-dd97-4a6e-c816-b0b239e79ef9"
   },
   "outputs": [],
   "source": [
    "model.save('fish2eat_model.h5')\n",
    "files.download('fish2eat_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePFie_A7RDbg"
   },
   "source": [
    "#Step 9: Save and Download Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "vk_sxUji_YZ8",
    "outputId": "fca33555-f8ed-454e-bdd7-580ea556de8e"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class_labels = {\n",
    "    0: 'Bandeng',\n",
    "    1: 'Gabus',\n",
    "    2: 'Gurame',\n",
    "    3: 'Kakap Merah',\n",
    "    4: 'Lele',\n",
    "    5: 'Mujair',\n",
    "    6: 'Nila',\n",
    "    7: 'Patin',\n",
    "    8: 'Salmon',\n",
    "    9: 'Sapu-sapu',\n",
    "    10: 'Sarden',\n",
    "    11: 'Tenggiri',\n",
    "    12: 'Teri',\n",
    "    13: 'Tongkol',\n",
    "    14: 'Tuna'\n",
    "}\n",
    "\n",
    "with open('labels.json', 'w') as f:\n",
    "    json.dump(class_labels, f)\n",
    "files.download('labels.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "migK4H21c41J"
   },
   "source": [
    "#Step 10: Predict and Display an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "U13VkkDfaive",
    "outputId": "d965874a-73b3-44fc-bbb5-01ce0c186c72"
   },
   "outputs": [],
   "source": [
    "def predict_upload_image(model, target_size=(150, 150)):\n",
    "    print(\"Upload an image to predict its class:\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for fn in uploaded.keys():\n",
    "\n",
    "        path = fn\n",
    "\n",
    "        img = load_img(path, target_size=target_size)\n",
    "        x = img_to_array(img)\n",
    "        x /= 255.0\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        predictions = model.predict(x)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        confidence = predictions[0][predicted_class]\n",
    "        predicted_class_label = class_labels[predicted_class]\n",
    "\n",
    "        print(f\"Predicted class for {fn}: {class_labels[predicted_class]} ({confidence*100:.2f}% confidence)\")\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Predicted class: {predicted_class_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "predict_upload_image(model, target_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ancrdyC3Wmcu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
